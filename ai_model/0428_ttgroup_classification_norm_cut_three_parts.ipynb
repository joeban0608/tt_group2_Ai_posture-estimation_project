{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "0428_ttgroup_classification_norm_cut_three_parts.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAHkfWvnejbK"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahnuW8rfKSkZ"
      },
      "source": [
        "#記得掛載雲端硬碟 \n",
        "from zipfile import ZipFile\n",
        "path = \"/content/drive/MyDrive/ttgroup/0_9000/0519_out_resize256x256_0_9000_json.zip\"\n",
        "f = ZipFile(path)\n",
        "# f.extractall() 小括號是直接解壓縮在同一層\n",
        "f.extractall()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNoY0fsKOqw3"
      },
      "source": [
        "# img_fn_df 圖片名稱DataFrame\n",
        "import glob\n",
        "import json, codecs\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "fn_dic = {\"img_name\":[]}\n",
        "# fn_dic_2 = []\n",
        "paths = sorted(glob.glob(\"/content/0519_out_resize256x256_0_9000_json/*\"))\n",
        "for path in paths:\n",
        "  fn_type = path.split(\"/\")[-1]\n",
        "  fn = fn_type.split(\".\")[0]\n",
        "  fn_dic[\"img_name\"].append(fn)\n",
        "  # fn_dic_2.append(fn)\n",
        "# print(fn_dic)\n",
        "fn_dic_df = pd.DataFrame(fn_dic)\n",
        "fn_dic_df\n",
        "# print(fn_dic_2)\n",
        "\n",
        "\n",
        "# file_path = \"/content/1162.json\"\n",
        "# for i in range(len(fs))\n",
        "# obj_text = codecs.open(paths[0], 'r', encoding='utf-8').read()\n",
        "# b_new = json.loads(obj_text)\n",
        "# a_new = np.array(b_new)\n",
        "# a_new"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHwkV0stfoHk"
      },
      "source": [
        "# create ans_df  驗證資料DataFrame\n",
        "import os\n",
        "base = \"/content/drive/MyDrive/ttgroup/0_9000/0519_wrong_total_sit_value_combinefoot_0_9000.csv\"\n",
        "sitting_csv = pd.read_csv(base, sep=\",\")\n",
        "ans_df = pd.DataFrame(sitting_csv)\n",
        "ans_df = ans_df.drop([\"img_name\"], axis=1)\n",
        "ans_df\n",
        "# ans = df[:1]\n",
        "# ans = ans.drop([\"img_name\"], axis=1)\n",
        "# ans\n",
        "# print(type(sitting_csv)\n",
        "# np.array(sitting_csv)\n",
        "ans_head_df = pd.DataFrame(ans_df[\"head\"])\n",
        "ans_shoulder_df = pd.DataFrame(ans_df[\"shoulder\"])\n",
        "# ans_footup_df = pd.DataFrame(ans_df[\"foot_up\"])\n",
        "# ans_footopen_df = pd.DataFrame(ans_df[\"foot_open\"])\n",
        "ans_foot_df = pd.DataFrame(ans_df[\"foot\"])\n",
        "ans_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4lzvj6i4C1m"
      },
      "source": [
        "# test ans_df\n",
        "ans_df\n",
        "ans_head_df\n",
        "ans_shoulder_df\n",
        "# ans_footup_df\n",
        "# ans_footopen_df\n",
        "ans_foot_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFlCfoeQl6ll"
      },
      "source": [
        "# create keypoints_36_combine_df \n",
        "\n",
        "import json, codecs\n",
        "import numpy as np\n",
        "columns ={\n",
        "     \"coco_col\":['Nose_x', 'Nose_y', 'Neck_x', 'Neck_y',\n",
        "           'R-Sho_x', 'R-Sho_y', 'R-Elb_x', 'R-Elb_y',\n",
        "           'R-Wr_x', 'R-Wr_y', 'L-Sho_x', 'L-Sho_y', \n",
        "           'L-Elb_x', 'L-Elb_y', 'L-Wr_x', 'L-Wr_y',\n",
        "           'R-Hip_x', 'R-Hip_y', 'R-Knee_x', 'R-Knee_y',\n",
        "           'R-Ank_x', 'R-Ank_y', 'L-Hip_x', 'L-Hip_y',\n",
        "           'L-Knee_x', 'L-Knee_y', 'L-Ank_x', 'L-Ank_y',\n",
        "           'R-Eye_x', 'R-Eye_y', 'L-Eye_x', 'L-Eye_y',\n",
        "           'R-Ear_x', 'R-Ear_y', 'L-Ear_x', 'L-Ear_y']\n",
        "    }\n",
        "fn_list = fn_dic[\"img_name\"]\n",
        "# print(fn_list) 印0004, 0006...\n",
        "\n",
        "# 運用globals()[] 全域變數：做成動態的變數名。\n",
        "n_fn_list = []\n",
        "for fn in fn_list:\n",
        "  # print(fn)\n",
        "  obj_text = codecs.open(\"/content/0519_out_resize256x256_0_9000_json/\"+ fn + \".json\", 'r', encoding='utf-8').read()\n",
        "  b_new = json.loads(obj_text)\n",
        "  a_new = np.array(b_new)\n",
        "  a_new = a_new.reshape(1,36)\n",
        "  # print(a_new)\n",
        "  globals()[\"key_point_36\"+ fn +\"_df\"] = pd.DataFrame(a_new, columns = columns[\"coco_col\"])\n",
        "  # print(globals()[\"key_point_36\"+ fn +\"_df\"])\n",
        "  n_fn_list.append(globals()[\"key_point_36\"+ fn +\"_df\"])\n",
        "# print(n_fn_list)\n",
        "\n",
        "# pd.concat([key_point_36_0004_df, key_point_36_0006_df, key_point_36_0008_df])\n",
        "key_point_36_combine_df = pd.concat(n_fn_list, ignore_index=True)\n",
        "key_point_36_combine_df\n",
        "\n",
        "# # bond.reset_index(inplace=True)\n",
        "# key_point_36_combine_df = key_point_36_combine_df.reset_index()\n",
        "# key_point_36_combine_df\n",
        "\n",
        "# # df.drop(columns=['B', 'C'])\n",
        "# # df.drop(['B', 'C'], axis=1)\n",
        "# key_point_36_combine_df = key_point_36_combine_df.drop(columns=['index'])\n",
        "# key_point_36_combine_df\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2k-JVPD_l0uK"
      },
      "source": [
        "# key_point_36_combine_normalize_preprocess\n",
        "\n",
        "key_point_36_combine_columns_list = columns[\"coco_col\"]\n",
        "# key_point_36_combine_df.columns.tolist()\n",
        "\n",
        "key_point_36_combine_row_list = []\n",
        "len(key_point_36_combine_df)\n",
        "\n",
        "for i in range(len(key_point_36_combine_df)):\n",
        "  globals()[\"key_point_36_combine_row\"+ str(i) +\"_df\"] = key_point_36_combine_df[i:i+1]\n",
        "  # key_point_36_combine_row0_df\n",
        "  \n",
        "  for key_point_36_combine_column in key_point_36_combine_columns_list:\n",
        "    if key_point_36_combine_column == \"Neck_x\":\n",
        "      continue\n",
        "    elif key_point_36_combine_column == \"Neck_y\":\n",
        "      continue\n",
        "    elif \"x\" in key_point_36_combine_column:\n",
        "        globals()[\"key_point_36_combine_row\"+ str(i) +\"_df\"][key_point_36_combine_column] = globals()[\"key_point_36_combine_row\"+ str(i) +\"_df\"][key_point_36_combine_column] - globals()[\"key_point_36_combine_row\"+ str(i) +\"_df\"][\"Neck_x\"]\n",
        "    elif \"y\" in key_point_36_combine_column:\n",
        "        globals()[\"key_point_36_combine_row\"+ str(i) +\"_df\"][key_point_36_combine_column] = globals()[\"key_point_36_combine_row\"+ str(i) +\"_df\"][key_point_36_combine_column] - globals()[\"key_point_36_combine_row\"+ str(i) +\"_df\"][\"Neck_y\"]\n",
        "  key_point_36_combine_row_list.append(globals()[\"key_point_36_combine_row\"+ str(i) +\"_df\"])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49jshaScGeaH"
      },
      "source": [
        "# normalize\n",
        "key_point_36_combine_norm_df = pd.concat(key_point_36_combine_row_list)\n",
        "key_point_36_combine_norm_df.loc[:,[\"Neck_x\",\"Neck_y\"]] = 0\n",
        "key_point_36_combine_norm_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Nx4-d_taKa3"
      },
      "source": [
        "# create key_point_36_combine_norm_cut_df\n",
        "\n",
        "# key_point_36_combine_norm_cut_head_df\n",
        "head_columns_list = ['Nose_x', 'Nose_y', 'Neck_x', 'Neck_y',         \n",
        "           'R-Eye_x', 'R-Eye_y', 'L-Eye_x', 'L-Eye_y',\n",
        "           'R-Ear_x', 'R-Ear_y', 'L-Ear_x', 'L-Ear_y'\n",
        "           ]\n",
        "key_point_36_combine_norm_cut_head_df = key_point_36_combine_norm_df[head_columns_list]\n",
        "\n",
        "# key_point_36_combine_norm_cut_shoulder_df\n",
        "shoulder_columns_list = ['Neck_x', 'Neck_y', 'R-Sho_x', 'R-Sho_y',\n",
        "              'L-Sho_x', 'L-Sho_y']\n",
        "#  \n",
        "# , 'L-Hip_x', 'L-Hip_y', 'R-Hip_x', 'R-Hip_y'\n",
        "key_point_36_combine_norm_cut_shoulder_df = key_point_36_combine_norm_df[shoulder_columns_list]\n",
        "key_point_36_combine_norm_cut_shoulder_df\n",
        "\n",
        "# key_point_36_combine_norm_cut_foot_df\n",
        "foot_columns_list = ['L-Hip_x', 'L-Hip_y', 'R-Hip_x', 'R-Hip_y',\n",
        "           'R-Knee_x', 'R-Knee_y', 'L-Knee_x', 'L-Knee_y', \n",
        "           'L-Ank_x', 'L-Ank_y', 'R-Ank_x', 'R-Ank_y',\n",
        "           ]\n",
        "key_point_36_combine_norm_cut_foot_df = key_point_36_combine_norm_df[foot_columns_list]\n",
        "key_point_36_combine_norm_cut_foot_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mb80G03d9LV-"
      },
      "source": [
        "# key_point_36_combine_df, ans_df\n",
        "pd.concat([key_point_36_combine_norm_cut_head_df , ans_head_df], axis=1)\n",
        "pd.concat([key_point_36_combine_norm_cut_shoulder_df , ans_shoulder_df], axis=1)\n",
        "# pd.concat([key_point_36_combine_norm_cut_foot_df , ans_footup_df], axis=1)\n",
        "# pd.concat([key_point_36_combine_norm_cut_foot_df , ans_footopen_df], axis=1)\n",
        "pd.concat([key_point_36_combine_norm_cut_foot_df , ans_foot_df], axis=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JKNPXAbkOse"
      },
      "source": [
        "# tran_test_split\n",
        "\n",
        "# head tran_test_split\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "x_train_hd, x_test_hd, y_train_hd, y_test_hd = train_test_split(np.array(key_point_36_combine_norm_cut_head_df),\n",
        "                             np.array(ans_head_df),\n",
        "                             test_size=0.1)\n",
        "\n",
        "# shoulder tran_test_split\n",
        "x_train_sho, x_test_sho, y_train_sho, y_test_sho = train_test_split(np.array(key_point_36_combine_norm_cut_shoulder_df),\n",
        "                             np.array(ans_shoulder_df),\n",
        "                             test_size=0.1)\n",
        "\n",
        "# # footup tran_test_split\n",
        "# x_train_ftup, x_test_ftup, y_train_ftup, y_test_ftup = train_test_split(np.array(key_point_36_combine_norm_cut_foot_df),\n",
        "#                              np.array(ans_footup_df),\n",
        "#                              test_size=0.1)\n",
        "\n",
        "# # footopen tran_test_split\n",
        "# x_train_ftop, x_test_ftop, y_train_ftop, y_test_ftop = train_test_split(np.array(key_point_36_combine_norm_cut_foot_df),\n",
        "#                              np.array(ans_footopen_df),\n",
        "#                              test_size=0.1)\n",
        "\n",
        "# foot tran_test_split\n",
        "x_train_ft, x_test_ft, y_train_ft, y_test_ft = train_test_split(np.array(key_point_36_combine_norm_cut_foot_df),\n",
        "                             np.array(ans_foot_df),\n",
        "                             test_size=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VA70hxP3lYS_"
      },
      "source": [
        "# check shape\n",
        "\n",
        "# head shape\n",
        "print(\"head:\", x_train_hd.shape)\n",
        "print(\"head:\", y_train_hd.shape)\n",
        "print(\"head:\", x_test_hd.shape)\n",
        "print(\"head:\", y_test_hd.shape)\n",
        "# shoulder shape\n",
        "print(\"shoulder:\", x_train_sho.shape)\n",
        "print(\"shoulder:\", y_train_sho.shape)\n",
        "print(\"shoulder:\", x_test_sho.shape)\n",
        "print(\"shoulder:\", y_test_sho.shape)\n",
        "# # footup shape\n",
        "# print(\"footup:\", x_train_ftup.shape)\n",
        "# print(\"footup:\", y_train_ftup.shape)\n",
        "# print(\"footup:\", x_test_ftup.shape)\n",
        "# print(\"footup:\", y_test_ftup.shape)\n",
        "# # footopen shape\n",
        "# print(\"footopen:\", x_train_ftop.shape)\n",
        "# print(\"footopen:\", y_train_ftop.shape)\n",
        "# print(\"footopen:\", x_test_ftop.shape)\n",
        "# print(\"footopen:\", y_test_ftop.shape)\n",
        "\n",
        "# foot shape\n",
        "print(\"footopen:\", x_train_ft.shape)\n",
        "print(\"footopen:\", y_train_ft.shape)\n",
        "print(\"footopen:\", x_test_ft.shape)\n",
        "print(\"footopen:\", y_test_ft.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9gMyAa3ltgl"
      },
      "source": [
        "# create DecisionTreeClassifier\n",
        "\n",
        "# head DecisionTreeClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "clf_hd = DecisionTreeClassifier(max_depth=4)\n",
        "clf_hd.fit(x_train_hd, y_train_hd)\n",
        "\n",
        "# shoulder DecisionTreeClassifier\n",
        "clf_sho = DecisionTreeClassifier(max_depth=3)\n",
        "clf_sho.fit(x_train_sho, y_train_sho)\n",
        "\n",
        "# foot DecisionTreeClassifier\n",
        "clf_ft = DecisionTreeClassifier(max_depth=3)\n",
        "clf_ft.fit(x_train_ft, y_train_ft)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtl7jkMr5iWA"
      },
      "source": [
        "# create feature_names,class_names\n",
        "\n",
        "# head feature_names,class_names\n",
        "head_columns_list\n",
        "class_names_hd_list = [\"head_correct\", \"head_wrong\"]\n",
        "\n",
        "# shoulder feature_names,class_names\n",
        "shoulder_columns_list\n",
        "class_names_sho_list = [\"sho_correct\", \"sho_wrong\"]\n",
        "\n",
        "# # footup feature_names,class_names\n",
        "# foot_columns_list\n",
        "# class_names_ftup_list = [\"no_footup\", \"footup\"]\n",
        "\n",
        "# # footopen feature_names,class_names\n",
        "# foot_columns_list\n",
        "# class_names_ftop_list = [\"no_footopen\", \"footopen\"]\n",
        "\n",
        "# foot feature_names,class_names\n",
        "foot_columns_list\n",
        "class_names_ft_list = [\"foot_correct\", \"foot_wrong\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwBzoogolvbi"
      },
      "source": [
        "# # plot DecisionTree\n",
        "\n",
        "# # head feature_names,class_names\n",
        "# from sklearn.tree import plot_tree\n",
        "# import matplotlib.pyplot as plt\n",
        "# plt.figure(figsize=(128, 128))\n",
        "# #figsize 這邊指畫布的height, weight\n",
        "# plot_tree(clf_hd,\n",
        "#      max_depth=2,\n",
        "#      feature_names=head_columns_list,\n",
        "#      class_names=class_names_hd_list,\n",
        "#      filled=True)\n",
        "\n",
        "# shoulder feature_names,class_names\n",
        "# plt.figure(figsize=(128, 128))\n",
        "# #figsize 這邊指畫布的height, weight\n",
        "# plot_tree(clf_sho,\n",
        "#      max_depth=2,\n",
        "#      feature_names=shoulder_columns_list,\n",
        "#      class_names=class_names_sho_list,\n",
        "#      filled=True)\n",
        "\n",
        "# # # footup feature_names,class_names\n",
        "# # plt.figure(figsize=(128, 128))\n",
        "# # #figsize 這邊指畫布的height, weight\n",
        "# # plot_tree(clf_ftup,\n",
        "# #      max_depth=2,\n",
        "# #      feature_names=foot_columns_list,\n",
        "# #      class_names=class_names_ftup_list,\n",
        "# #      filled=True)\n",
        "\n",
        "# # # footup feature_names,class_names\n",
        "# # plt.figure(figsize=(128, 128))\n",
        "# # #figsize 這邊指畫布的height, weight\n",
        "# # plot_tree(clf_ftup,\n",
        "# #      max_depth=2,\n",
        "# #      feature_names=foot_columns_list,\n",
        "# #      class_names=class_names_ftop_list,\n",
        "# #      filled=True)\n",
        "\n",
        "# # foot feature_names,class_names\n",
        "# plt.figure(figsize=(128, 128))\n",
        "# #figsize 這邊指畫布的height, weight\n",
        "# plot_tree(clf_ft,\n",
        "#      max_depth=2,\n",
        "#      feature_names=foot_columns_list,\n",
        "#      class_names=class_names_ft_list,\n",
        "#      filled=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFcaXxZXmdQd"
      },
      "source": [
        "# proba:accuracy_score\n",
        "\n",
        "# head accuracy_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "pre_hd = clf_hd.predict(x_test_hd)\n",
        "print(\"proba_head_worng_accuracy_score:\", accuracy_score(pre_hd, y_test_hd))\n",
        "\n",
        "# shoulder accuracy_score\n",
        "pre_sho = clf_sho.predict(x_test_sho)\n",
        "print(\"proba_shoulder_worng_accuracy_score:\", accuracy_score(pre_sho, y_test_sho))\n",
        "\n",
        "# # footup accuracy_score\n",
        "# pre_ftup = clf_ftup.predict(x_test_ftup)\n",
        "# print(\"proba_footup_accuracy_score:\", accuracy_score(pre_ftup, y_test_ftup))\n",
        "\n",
        "# # footop accuracy_score\n",
        "# pre_ftop = clf_ftop.predict(x_test_ftop)\n",
        "# print(\"proba_footopen_accuracy_score:\", accuracy_score(pre_ftop, y_test_ftop))\n",
        "\n",
        "# foot accuracy_score\n",
        "pre_ft = clf_ft.predict(x_test_ft)\n",
        "print(\"proba_foot_accuracy_score:\", accuracy_score(pre_ft, y_test_ft))\n",
        "# print(pre_ft)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RsNGFPE7bTf"
      },
      "source": [
        "**label_accuracy**\n",
        "1. 分四個class的accuracy_score:0.6-0.85\n",
        "2. 分三個class的accuracy_score:0.8-0.9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGTQccrXpGdF"
      },
      "source": [
        "**shoulder_accuracy**\n",
        "1. nose,neck,shoulder: 0.75, 0.875, 0.9, 0.925, 0.875, 0.825, 0.875, 0.9\n",
        "  **Range**:0.825-0.925  **Average**:0.865625\n",
        "2. nose,neck,shoulder,hip: 0.8, 0.85, 0.925, 0.85, 0.85, 0.9, 0.825, 0.875\n",
        "  **Rrange**:0.8-0.925  **Average**:0.859375\n",
        "3. neck,shoulder,hip: 0.85, 0.9, 0.825, 0.875, 0.85, 0.825, 0.85, 0.8\n",
        "  **Rrange**:0.8-0.9   **Average**:0.846875\n",
        "4. neck,shoulder: 0.9, 0.825, 0.725, 0.85, 0.85, 0.825, 0.825, 0.8\n",
        "  **Rrange**:0.725-0.9   **Average**:0.825\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SD2r-bYvZjHr"
      },
      "source": [
        "# input_test\n",
        "# fn = input(\"請輸入檔名:\")\n",
        "obj_text = codecs.open(fn, 'r', encoding='utf-8').read()\n",
        "b_new = json.loads(obj_text)\n",
        "a_new = np.array(b_new)\n",
        "a_new = a_new.reshape(1,36)\n",
        "input_key_point_36_df = pd.DataFrame(a_new, columns=key_point_36_combine_columns_list)\n",
        "input_key_point_36_df\n",
        "\n",
        "# input_key_point_36_df[\"Neck_x\"]\n",
        "# Normaolize\n",
        "for key_point_36_combine_column in key_point_36_combine_columns_list:\n",
        "  if key_point_36_combine_column == \"Neck_x\":\n",
        "    continue\n",
        "  elif key_point_36_combine_column == \"Neck_y\":\n",
        "    continue\n",
        "  elif \"x\" in key_point_36_combine_column:\n",
        "      input_key_point_36_df[key_point_36_combine_column] = input_key_point_36_df[key_point_36_combine_column] - input_key_point_36_df[\"Neck_x\"]\n",
        "  elif \"y\" in key_point_36_combine_column:\n",
        "      input_key_point_36_df[key_point_36_combine_column] = input_key_point_36_df[key_point_36_combine_column] - input_key_point_36_df[\"Neck_y\"]\n",
        "# input_key_point_36_df\n",
        "input_key_point_36_df.loc[:,[\"Neck_x\",\"Neck_y\"]] = 0\n",
        "input_key_point_36_norm_df = input_key_point_36_df\n",
        "# input_key_point_36_df.shape\n",
        "\n",
        "# cut three part\n",
        "x_test_hd_in = input_key_point_36_norm_df[head_columns_list]\n",
        "x_test_sho_in = input_key_point_36_norm_df[shoulder_columns_list]\n",
        "x_test_ft_in = input_key_point_36_norm_df[foot_columns_list]\n",
        "\n",
        "# 分類\n",
        "# clf_hd_np = clf_hd.predict(x_test_in)\n",
        "# clf_sho_np = clf_sho.predict(x_test_in)\n",
        "# clf_ft_np = clf_ft.predict(x_test_in)\n",
        "# np.hstack((a,b))水平組合\n",
        "# clf_np_list = np.hstack((clf_hd_np, clf_sho_np, clf_ft_np))\n",
        "\n",
        "# 機率\n",
        "hd_wrong_proba = clf_hd.predict_proba(x_test_hd_in)[0][1]\n",
        "sho_wrong_proba = clf_sho.predict_proba(x_test_sho_in)[0][1]\n",
        "ft_wrong_proba = clf_ft.predict_proba(x_test_ft_in)[0][1]\n",
        "# np.hstack((a,b))水平組合\n",
        "# 做出head, shoulder, foot的機率清單\n",
        "clf_proba_list = np.hstack((hd_wrong_proba, sho_wrong_proba, ft_wrong_proba)).tolist()\n",
        "print(\"head,shoulder,foot/proba:\",clf_proba_list)\n",
        "\n",
        "# 將機率清單轉成T&F\n",
        "ans_names = ans_df.columns.tolist()\n",
        "ans_list = []\n",
        "for i, ans_name in enumerate(ans_names):\n",
        "  ans = round(clf_proba_list[i])\n",
        "  ans_list.append(ans)\n",
        "print(\"T&F:\", ans_list)\n",
        "\n",
        "# 將hd,sho,ft 分別指出錯誤跟正確的部位。\n",
        "correct = []\n",
        "wrong = []\n",
        "for i, ans_val in enumerate(ans_list):\n",
        "  if ans_val == 1:\n",
        "    wrong.append(ans_names[i])\n",
        "  else:\n",
        "    correct.append(ans_names[i])\n",
        "print(\"correct:\", correct)\n",
        "print(\"wrong:\", wrong)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}